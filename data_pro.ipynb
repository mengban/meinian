{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57298\n",
      "2800\n"
     ]
    }
   ],
   "source": [
    "vid=[]\n",
    "table_id=[]\n",
    "field_results=[]\n",
    "def line2list(filename):\n",
    "    line = []\n",
    "    with open(filename,'r',encoding='utf-8') as wf:\n",
    "        item = wf.readline()\n",
    "        while item:\n",
    "            item=item.replace('\\n','')\n",
    "            line.append(item)\n",
    "            item = wf.readline()\n",
    "    return line\n",
    "    \n",
    "vid=line2list('tabVid_1.txt')\n",
    "    #vid=vid+line2list('tabVid_2.txt')\\n ,\n",
    "table_id=line2list('featureTab1.txt')\n",
    "table_id=table_id+line2list('featureTab2.txt')\n",
    "print(len(vid))\n",
    "print(len(table_id))\n",
    "\n",
    "dic={}\n",
    "for user in vid:\n",
    "    dic_user={}\n",
    "    for feature in table_id:\n",
    "        dic_user[feature]='*'\n",
    "    dic[user]=dic_user\n",
    "     \n",
    "\n",
    "     #with open('meinian_round1_data_part2_20180408.txt','r',encoding='utf-8') as wf:\\n ,\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " deal with line 100000\n",
      " deal with line 200000\n",
      " deal with line 300000\n",
      " deal with line 400000\n",
      " deal with line 500000\n",
      " deal with line 600000\n",
      " deal with line 700000\n",
      " deal with line 800000\n",
      " deal with line 900000\n",
      " deal with line 1000000\n",
      " deal with line 1100000\n",
      " deal with line 1200000\n",
      " deal with line 1300000\n",
      " deal with line 1400000\n",
      " deal with line 1500000\n",
      " deal with line 1600000\n",
      " deal with line 1700000\n",
      " deal with line 1800000\n",
      " deal with line 1900000\n",
      " deal with line 2000000\n",
      " deal with line 2100000\n",
      " deal with line 2200000\n",
      " deal with line 2300000\n",
      " deal with line 2400000\n",
      " deal with line 2500000\n",
      " deal with line 2600000\n",
      " deal with line 2700000\n",
      " deal with line 2800000\n",
      " deal with line 2900000\n",
      " deal with line 3000000\n",
      " deal with line 3100000\n",
      " deal with line 3200000\n",
      " deal with line 3300000\n",
      " deal with line 3400000\n",
      " deal with line 3500000\n",
      " deal with line 3600000\n",
      " deal with line 3700000\n",
      " deal with line 3800000\n",
      " deal with line 3900000\n",
      " deal with line 4000000\n",
      " deal with line 4100000\n",
      " deal with line 4200000\n",
      " deal with line 4300000\n",
      " deal with line 4400000\n",
      " deal with line 100000\n",
      " deal with line 200000\n",
      " deal with line 300000\n",
      " deal with line 400000\n",
      " deal with line 500000\n",
      " deal with line 600000\n",
      " deal with line 700000\n",
      " deal with line 800000\n",
      " deal with line 900000\n",
      " deal with line 1000000\n",
      " deal with line 1100000\n",
      " deal with line 1200000\n",
      " deal with line 1300000\n",
      " deal with line 1400000\n",
      " deal with line 1500000\n",
      " deal with line 1600000\n",
      " deal with line 1700000\n",
      " deal with line 1800000\n",
      " deal with line 1900000\n",
      " deal with line 2000000\n",
      " deal with line 2100000\n",
      " deal with line 2200000\n",
      " deal with line 2300000\n",
      " deal with line 2400000\n",
      " deal with line 2500000\n",
      " deal with line 2600000\n",
      " deal with line 2700000\n",
      " deal with line 2800000\n",
      " deal with line 2900000\n",
      " deal with line 3000000\n",
      " deal with line 3100000\n",
      " deal with line 3200000\n",
      " deal with line 3300000\n",
      " deal with line 3400000\n",
      " deal with line 3500000\n",
      " deal with line 3600000\n"
     ]
    }
   ],
   "source": [
    "#with open('test1000.txtaa','r',encoding='utf-8') as wf:\n",
    "with open('meinian_round1_data_part1_20180408.txt','r',encoding='utf-8') as wf:   \n",
    "    count=1\n",
    "    item=wf.readline()\n",
    "    while item:\n",
    "        tmp = item.split('$')\n",
    "        tmp[2]=tmp[2].replace('\\n','')\n",
    "        if tmp[0] in dic.keys():\n",
    "            if tmp[1] in dic[tmp[0]].keys():\n",
    "                dic[tmp[0]][tmp[1]]=tmp[2]\n",
    "        if count%100000==0:\n",
    "            print(' deal with line',count)\n",
    "        item=wf.readline()\n",
    "        count+=1\n",
    "with open('meinian_round1_data_part2_20180408.txt','r',encoding='utf-8') as wf:   \n",
    "    count=1\n",
    "    item=wf.readline()\n",
    "    while item:\n",
    "        tmp = item.split('$')\n",
    "        tmp[2]=tmp[2].replace('\\n','')\n",
    "        if tmp[0] in dic.keys():\n",
    "            if tmp[1] in dic[tmp[0]].keys():\n",
    "                dic[tmp[0]][tmp[1]]=tmp[2]\n",
    "        if count%100000==0:\n",
    "            print(' deal with line',count)\n",
    "        item=wf.readline()\n",
    "        count+=1\n",
    "        \n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "save=DataFrame(dic)\n",
    "save.T.to_csv('outT.txt',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2795"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic[tmp[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "save=DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save.to_csv('out.txt',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save.T.to_csv('outT__.csv',sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
